{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdb31713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c226fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Specify the path to OpenSlide bin directory (for Windows).\n",
    "openslide_bin_path = r'C:\\Users\\balin\\Desktop\\Tools\\openslide-bin-4.0.0.8-windows-x64\\bin' \n",
    "\n",
    "# Add the DLL directory to the PATH for Python >= 3.8\n",
    "if hasattr(os, 'add_dll_directory'):\n",
    "    os.add_dll_directory(openslide_bin_path)\n",
    "else:\n",
    "    # Fallback for Python < 3.8 (add to system PATH, less ideal but works)\n",
    "    os.environ['PATH'] = openslide_bin_path + os.pathsep + os.environ['PATH']\n",
    "\n",
    "# --- Now you can import openslide ---\n",
    "import openslide\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2c167c",
   "metadata": {},
   "source": [
    "Stage 1: Intro to Histopathology & Image Handling\n",
    "Objective: Learn how to handle pathology image data (patching, preprocessing)\n",
    "Tasks:\n",
    "Introduction to Whole Slide Image (WSI) formats such as .svs and .tif\n",
    "Load and extract image patches from WSI using OpenSlide\n",
    "Resize, normalize, and apply augmentations to image patches\n",
    "Manage labels for patches (e.g., tumor vs. normal)\n",
    "Sample Dataset:\n",
    "CAMELYON16 dataset: https://camelyon16.grand-challenge.org/\n",
    "PatchCamelyon (PCam): https://github.com/basveeling/pcam\n",
    "Deliverables:\n",
    "Code that extracts 224x224 patches from WSIs with appropriate labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52328884",
   "metadata": {},
   "source": [
    "CAMELYON16 dataset is huge! >3.6Tb. Not enough local memory to work with entire dataset. For instructional purposes, so only going to download first 3 Normal slides and first 3 Tumour slides and work with these for now. For Stage 2, will use smaller PCam dataset where patching and labelleing has already been done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dd85e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3564d0b9",
   "metadata": {},
   "source": [
    "Stage 2: Basic Classification with CNNs\n",
    "Objective: Train a Convolutional Neural Network (CNN) on pathology patches\n",
    "Tasks:\n",
    "Perform train/test split on image patches\n",
    "Build a simple CNN using Keras or PyTorch\n",
    "Evaluate performance using metrics such as accuracy, sensitivity, and specificity\n",
    "Visualize predictions, such as generating heatmaps overlaying WSIs\n",
    "Deliverables:\n",
    "A working classification model that distinguishes between tumor and normal patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ecf9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "861c45de",
   "metadata": {},
   "source": [
    "Stage 3: Advanced Deep Learning\n",
    "Objective: Implement transfer learning and segmentation models\n",
    "Tasks:\n",
    "Utilize transfer learning with models like ResNet or EfficientNet\n",
    "Apply semantic segmentation techniques using U-Net or similar architectures\n",
    "Train segmentation models on labeled datasets for nuclei or tissue segmentation\n",
    "Sample Dataset:\n",
    "MoNuSeg (nuclei segmentation): https://monuseg.grand-challenge.org/\n",
    "PanNuke dataset: https://warwick.ac.uk/fac/cross_fac/tia/data/pannuke\n",
    "Deliverables:\n",
    "A segmentation model that outputs accurate masks\n",
    "Visual overlays of segmented areas on original patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd59810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdeedc2b",
   "metadata": {},
   "source": [
    "Stage 4: Multi-Modal Integration & Explainability\n",
    "Objective: Integrate clinical metadata and understand model decision-making\n",
    "Tasks:\n",
    "Combine image data with patient metadata (e.g., CSV files)\n",
    "Use model interpretability tools such as SHAP or Grad-CAM\n",
    "Evaluate model performance with and without metadata\n",
    "Deliverables:\n",
    "A multi-modal AI model incorporating metadata\n",
    "Grad-CAM visualizations highlighting decision-influencing regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30184b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66b0b366",
   "metadata": {},
   "source": [
    "Stage 5: Disease-Specific Mini Project\n",
    "Objective: Apply learned skills to a real dataset from clinicians\n",
    "Tasks:\n",
    "Receive a small set of WSIs and associated labels for a specific disease (e.g., breast cancer)\n",
    "Preprocess, extract patches, and label the data accordingly\n",
    "Train and evaluate a classification or segmentation model\n",
    "Write a mini-report with evaluation metrics such as confusion matrix and ROC curves\n",
    "Deliverables:\n",
    "A fully functional analysis pipeline ready to handle clinical data\n",
    "A report summarizing methods, results, and insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87805e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ec47b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce72e965",
   "metadata": {},
   "source": [
    "Optional Stage 6: Deployment\n",
    "Objective: Convert model into a deployable tool or clinical viewer\n",
    "Tasks:\n",
    "Modularize code into reusable scripts\n",
    "Save trained model in a deployable format (e.g., .h5 or TorchScript)\n",
    "Develop a simple viewer/dashboard using Streamlit or Flask\n",
    "Deliverables:\n",
    "A deployable AI model for pathology tasks\n",
    "A simple web interface to demonstrate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1354a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
